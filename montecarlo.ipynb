{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmEKeoOKFSJoHaAj28fy6j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yash361-code/reinforcement_learning01/blob/main/montecarlo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV58iT_-OgQy"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from collections import defaultdict\n",
        "from functools import partial\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('Blackjack-v1')"
      ],
      "metadata": {
        "id": "i4sqXjVuOugc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_policy(observation):\n",
        "    score, dealer_score, usable_ace = observation\n",
        "    return 0 if score >= 20 else 1"
      ],
      "metadata": {
        "id": "l-ni3gKDOw1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states, actions, rewards = [], [], []\n",
        "def generate_episode(policy, env):\n",
        "\n",
        "  observation = env.reset()\n",
        "\n",
        "  while True:\n",
        "    states.append(observation)\n",
        "\n",
        "    action = sample_policy(observation)\n",
        "    actions.append(observation)\n",
        "\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    rewards.append(reward)\n",
        "    if done:\n",
        "      break\n",
        "  return states, actions, rewards"
      ],
      "metadata": {
        "id": "VyZbr0UVO4O2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def first_visit_mc_prediction(policy, env, n_episodes):\n",
        "    value_table = defaultdict(float)\n",
        "    N = defaultdict(int)\n",
        "\n",
        "    for _ in range(n_episodes):\n",
        "        states, _, rewards = generate_episode(policy, env)\n",
        "        returns = 0\n",
        "\n",
        "        for t in range(len(states) - 1, -1, -1):\n",
        "            R = rewards[t]\n",
        "            S = states[t]\n",
        "            \n",
        "            returns += R      \n",
        "            if S not in states[:t]:\n",
        "                N[S] += 1\n",
        "                value_table[S] += (returns - value_table[S]) / N[S]\n",
        "    \n",
        "    return value_table"
      ],
      "metadata": {
        "id": "yymZlW4fO7_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value = first_visit_mc_prediction(sample_policy, env, n_episodes=10000)"
      ],
      "metadata": {
        "id": "cRYi9M7dPArI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(value.popitem())\n",
        "  \n",
        "print(states)\n",
        "print(actions)\n",
        "print(rewards)"
      ],
      "metadata": {
        "id": "Ar7NHRjMPDX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_blackjack(V, ax1, ax2):\n",
        "    player_sum = np.arange(12, 21 + 1)\n",
        "    dealer_show = np.arange(1, 10 + 1)\n",
        "    usable_ace = np.array([False, True])\n",
        "    state_values = np.zeros((len(player_sum), len(dealer_show), len(usable_ace)))\n",
        "\n",
        "    for i, player in enumerate(player_sum):\n",
        "        for j, dealer in enumerate(dealer_show):\n",
        "            for k, ace in enumerate(usable_ace):\n",
        "                state_values[i, j, k] = V[player, dealer, ace]\n",
        "    \n",
        "    X, Y = np.meshgrid(player_sum, dealer_show)\n",
        " \n",
        "    ax1.plot_wireframe(X, Y, state_values[:, :, 0])\n",
        "    ax2.plot_wireframe(X, Y, state_values[:, :, 1])\n",
        " \n",
        "    for ax in ax1, ax2:\n",
        "        ax.set_zlim(-1, 1)\n",
        "        ax.set_ylabel('player sum')\n",
        "        ax.set_xlabel('dealer showing')\n",
        "        ax.set_zlabel('state-value')\n",
        "        \n",
        "fig, axes = pyplot.subplots(nrows=2, figsize=(5, 8),\n",
        "subplot_kw={'projection': '3d'})\n",
        "axes[0].set_title('value function without usable ace')\n",
        "axes[1].set_title('value function with usable ace')\n",
        "plot_blackjack(value, axes[0], axes[1])"
      ],
      "metadata": {
        "id": "lt7rTus6PHsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ioMUgggFPODg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}